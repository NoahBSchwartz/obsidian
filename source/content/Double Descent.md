hmm double descent is almost evidence for singular learning theory. where we have a phase change between simpler model to more complex model (ie. learning coefficient becomes larger and so our model does better). the first time our model fits the data we have no options for models to choose from. But when we have more parameters than variables, we actually do better because we can pick the solution with the lowest squared l2 norm (ie. the one thatâ€™s best able to generalize)


bias variance curve is initially true but then we get more degrees to work with and our